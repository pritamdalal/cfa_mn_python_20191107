{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutoral 12 - OCC Volume Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this analysis is to put together a variety of the skills we have learned in previous tutorials to do a bit of analysis work that's akin to something you might do in a professional context.  The analysis will consist of:\n",
    "\n",
    "1. Producing a volume-by-underlying report from a data file sourced from the Options Clearing Corporation (OCC).  The data in the OCC file is for the month of August 2018. The data is far more granular than we need, so we will need to group and summarize (a very common task in data analysis).  \n",
    "\n",
    "2. Combine the monthly volume report with master list of ETFs to determine the 100 highest volumne non-volatility ETFs.\n",
    "\n",
    "\n",
    "Don't worry if you are not familiar with the finance concepts discussed in this tutorial, it is my intention to focus on the mechanics of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` package contains much of the data wrangling functionality that we will need.  For those of you who are familiar with R, you can thing of `pandas` as the Python equivalent of R's `tidyverse`, however `pandas` has a larger scope than the core tidyverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> import numpy as np\n",
    "##> import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In theory you can give *pandas* any alias that you want, but it would be *highly* non-pythonic to call it anything other than **pd**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to make a couple of changes to the way that the notebook behaves (both of these are largely a matter of preference). This first bit of code changes the maximimun number of rows that will be displayed when we print a `DataFrame`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> pd.options.display.max_rows = 6\n",
    "\n",
    "pd.options.display.max_rows = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will make it so that the output of every line of code in a cell is printed.  The default behavior is that only the last line of code is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading In Data from a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` library has a `.read_csv()` method that will read in a table of data from a CSV and put it in a `DataFrame`, which is the main data object in `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_occ = pd.read_csv('data/occ_option_volume_201808.csv')\n",
    "##> df_occ.head()\n",
    "\n",
    "df_occ = pd.read_csv('../data/occ_option_volume_201808.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Exploration of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is a monthly option volume report from the OCC.  The data is broken down by trade-date, underlying, account type, puts/calls, and exchange. We can print a the contents of the `DataFrame` by simply typing its name and then running that code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantity</th>\n",
       "      <th>underlying</th>\n",
       "      <th>symbol</th>\n",
       "      <th>actype</th>\n",
       "      <th>porc</th>\n",
       "      <th>exchange</th>\n",
       "      <th>actdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5850</td>\n",
       "      <td>ABX</td>\n",
       "      <td>1ABX</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>AMEX</td>\n",
       "      <td>08/02/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3050</td>\n",
       "      <td>ABX</td>\n",
       "      <td>1ABX</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>AMEX</td>\n",
       "      <td>08/16/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3050</td>\n",
       "      <td>ABX</td>\n",
       "      <td>1ABX</td>\n",
       "      <td>F</td>\n",
       "      <td>C</td>\n",
       "      <td>AMEX</td>\n",
       "      <td>08/16/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870438</th>\n",
       "      <td>1</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>M</td>\n",
       "      <td>P</td>\n",
       "      <td>EDGX</td>\n",
       "      <td>08/20/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870439</th>\n",
       "      <td>25</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>MCRY</td>\n",
       "      <td>08/30/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870440</th>\n",
       "      <td>25</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>MCRY</td>\n",
       "      <td>08/30/2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1870441 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         quantity underlying symbol actype porc exchange     actdate\n",
       "0            5850        ABX   1ABX      C    C     AMEX  08/02/2018\n",
       "1            3050        ABX   1ABX      C    C     AMEX  08/16/2018\n",
       "2            3050        ABX   1ABX      F    C     AMEX  08/16/2018\n",
       "...           ...        ...    ...    ...  ...      ...         ...\n",
       "1870438         1       ZYNE   ZYNE      M    P     EDGX  08/20/2018\n",
       "1870439        25       ZYNE   ZYNE      C    C     MCRY  08/30/2018\n",
       "1870440        25       ZYNE   ZYNE      M    C     MCRY  08/30/2018\n",
       "\n",
       "[1870441 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_occ\n",
    "\n",
    "df_occ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice at the very bottom that the total number of rows and columns has been printed.  We can also get this information from the `.shape` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1870441, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_occ.shape\n",
    "\n",
    "df_occ.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `type()` function is also useful for exploring objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's first create a list object to test on.\n",
    "##> my_list = [1, \"twelve\", False]\n",
    "\n",
    "\n",
    "# then let's check the type of my_list as well as df_occ\n",
    "##> type(my_list)\n",
    "##> type(df_occ)\n",
    "\n",
    "type(df_occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the data type of each of the columns with the `.dtypes` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quantity       int64\n",
       "underlying    object\n",
       "symbol        object\n",
       "               ...  \n",
       "porc          object\n",
       "exchange      object\n",
       "actdate       object\n",
       "Length: 7, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_occ.dtypes\n",
    "\n",
    "df_occ.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all the string colums are given a data type of `object`.  Also notice that the `actdate` column was read in as a string, rather than a date, which we will fix later in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the columns of a dataframe by use of th `[` notation as well as the `.` notation.  Let's use both of these approaches to isolate the `underlying` column of `df_occ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           ABX\n",
       "1           ABX\n",
       "2           ABX\n",
       "           ... \n",
       "1870438    ZYNE\n",
       "1870439    ZYNE\n",
       "1870440    ZYNE\n",
       "Name: underlying, Length: 1870441, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0           ABX\n",
       "1           ABX\n",
       "2           ABX\n",
       "           ... \n",
       "1870438    ZYNE\n",
       "1870439    ZYNE\n",
       "1870440    ZYNE\n",
       "Name: underlying, Length: 1870441, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# both of these are equivalent\n",
    "##> df_occ['underlying']\n",
    "##> df_occ.underlying\n",
    "\n",
    "df_occ['underlying']\n",
    "df_occ.underlying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the the `type()` function to see that a column of a `DataFrame` is a `Series`, which is a different kind of `pandas` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> type(df_occ['underlying'])\n",
    "##> type(df_occ.underlying)\n",
    "\n",
    "type(df_occ['underlying'])\n",
    "type(df_occ.underlying)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't get into the weeds about this point too much, but it is worth noting that a `DataFrame` is a bunch of `Series` glued together.  For those of you familiar with R, this is similar the fact that a `data.frame` is a `list` of atomic vectors, all of the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactoring the Date Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we saw that the `df_occ.actdate` is infact an `object` data type, rather than a date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's compare the dtype of the df_occ.quantity and df_occ.actdate\n",
    "##> df_occ.quantity.dtype\n",
    "##> df_occ.actdate.dtype\n",
    "\n",
    "df_occ.quantity.dtype\n",
    "df_occ.actdate.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `pandas.to_datetime()` function for the purposes of this refactoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2018-08-02\n",
       "1         2018-08-16\n",
       "2         2018-08-16\n",
       "             ...    \n",
       "1870438   2018-08-20\n",
       "1870439   2018-08-30\n",
       "1870440   2018-08-30\n",
       "Name: actdate, Length: 1870441, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> pd.to_datetime(df_occ.actdate, format='%m/%d/%Y')\n",
    "\n",
    "pd.to_datetime(df_occ.actdate, format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this code above doesn't actually change `df_occ.actdate` but rather creates a new `Series` and prints it to the output.  We can test this by checking the `dtype` property of the column again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_occ.actdate.dtype\n",
    "\n",
    "df_occ.actdate.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to actually affect the change we are looking for, we need to reassign to `df_occ.actdate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_occ.actdate = pd.to_datetime(df_occ.actdate, format = '%m/%d/%Y')\n",
    "\n",
    "df_occ.actdate = pd.to_datetime(df_occ.actdate, format = '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the refactoring from `object` to `date` has actually occured.  Let's check the `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quantity               int64\n",
       "underlying            object\n",
       "symbol                object\n",
       "                   ...      \n",
       "porc                  object\n",
       "exchange              object\n",
       "actdate       datetime64[ns]\n",
       "Length: 7, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_occ.dtypes\n",
    "\n",
    "df_occ.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Exploration - Unique Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you first encounter a data set, it is useful to explore the unique values in some of the columns to try to get a feel for what is in the data set.  Let's look at the `underlying` column and the `actdate` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018-08-02T00:00:00.000000000', '2018-08-16T00:00:00.000000000',\n",
       "       '2018-08-13T00:00:00.000000000', '2018-08-09T00:00:00.000000000',\n",
       "       '2018-08-10T00:00:00.000000000', '2018-08-22T00:00:00.000000000',\n",
       "       '2018-08-06T00:00:00.000000000', '2018-08-15T00:00:00.000000000',\n",
       "       '2018-08-23T00:00:00.000000000', '2018-08-24T00:00:00.000000000',\n",
       "       '2018-08-07T00:00:00.000000000', '2018-08-21T00:00:00.000000000',\n",
       "       '2018-08-14T00:00:00.000000000', '2018-08-01T00:00:00.000000000',\n",
       "       '2018-08-03T00:00:00.000000000', '2018-08-17T00:00:00.000000000',\n",
       "       '2018-08-30T00:00:00.000000000', '2018-08-31T00:00:00.000000000',\n",
       "       '2018-08-27T00:00:00.000000000', '2018-08-20T00:00:00.000000000',\n",
       "       '2018-08-08T00:00:00.000000000', '2018-08-28T00:00:00.000000000',\n",
       "       '2018-08-29T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_occ.actdate.unique()\n",
    "\n",
    "df_occ.actdate.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our dates are all in August of 2018, but it's hard to be sure from visual inspection because the priting is messy.  Let's use the `min` and `max` methods just to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2018-08-01T00:00:00.000000000')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2018-08-31T00:00:00.000000000')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_occ.actdate.unique().min()\n",
    "##> df_occ.actdate.unique().max()\n",
    "\n",
    "df_occ.actdate.unique().min()\n",
    "df_occ.actdate.unique().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next look at the unique values of `underlying` - there are a lot of them so they are not all printed.  Notice that the `.unique()` method returns an `array` object.  In fact this is a `ndarray` which is the foundation data structure of `numpy`.  The `pandas` package is built on top of `numpy`.\n",
    "\n",
    "\n",
    "Let's check the size of the array, with the `.size` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ABX', 'AGI', 'ALB', ..., 'ZUMZ', 'ZUO', 'ZYNE'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4243"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_occ.underlying.unique()\n",
    "##> df_occ.underlying.unique().size\n",
    "\n",
    "df_occ.underlying.unique()\n",
    "df_occ.underlying.unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Codinge Challenge:** How many individual dates are represented in the `df_occ`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping And Summarizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ultimate objective is to know the total option volume for each underlying in the month of August 2018.  The data in it's current form is far more granular than that.  We will do some aggregation in order to get the data in the form that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantity</th>\n",
       "      <th>underlying</th>\n",
       "      <th>symbol</th>\n",
       "      <th>actype</th>\n",
       "      <th>porc</th>\n",
       "      <th>exchange</th>\n",
       "      <th>actdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5850</td>\n",
       "      <td>ABX</td>\n",
       "      <td>1ABX</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>AMEX</td>\n",
       "      <td>2018-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3050</td>\n",
       "      <td>ABX</td>\n",
       "      <td>1ABX</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>AMEX</td>\n",
       "      <td>2018-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3050</td>\n",
       "      <td>ABX</td>\n",
       "      <td>1ABX</td>\n",
       "      <td>F</td>\n",
       "      <td>C</td>\n",
       "      <td>AMEX</td>\n",
       "      <td>2018-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870438</th>\n",
       "      <td>1</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>M</td>\n",
       "      <td>P</td>\n",
       "      <td>EDGX</td>\n",
       "      <td>2018-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870439</th>\n",
       "      <td>25</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>MCRY</td>\n",
       "      <td>2018-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870440</th>\n",
       "      <td>25</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>MCRY</td>\n",
       "      <td>2018-08-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1870441 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         quantity underlying symbol actype porc exchange    actdate\n",
       "0            5850        ABX   1ABX      C    C     AMEX 2018-08-02\n",
       "1            3050        ABX   1ABX      C    C     AMEX 2018-08-16\n",
       "2            3050        ABX   1ABX      F    C     AMEX 2018-08-16\n",
       "...           ...        ...    ...    ...  ...      ...        ...\n",
       "1870438         1       ZYNE   ZYNE      M    P     EDGX 2018-08-20\n",
       "1870439        25       ZYNE   ZYNE      C    C     MCRY 2018-08-30\n",
       "1870440        25       ZYNE   ZYNE      M    C     MCRY 2018-08-30\n",
       "\n",
       "[1870441 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_occ\n",
    "\n",
    "df_occ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need to do is sum up the total quantity for each underlying.  We can do this with the `groupby()` method couple with the `sum()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "underlying\n",
       "A        166644\n",
       "AA       612596\n",
       "AABA    2914502\n",
       "         ...   \n",
       "ZUMZ       9882\n",
       "ZUO      168444\n",
       "ZYNE      36008\n",
       "Name: quantity, Length: 4243, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_occ.groupby('underlying')['quantity'].sum()\n",
    "\n",
    "\n",
    "df_occ.groupby('underlying')['quantity'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is actually a `Series` object, not a `DataFrame`. (Which is different than how `summarize()` works in `dplyr`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> type(df_occ.groupby('underlying')['quantity'].sum())\n",
    "\n",
    "type(df_occ.groupby('underlying')['quantity'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert this to a `DataFrame` using the `Series.to_frame()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>underlying</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>166644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>612596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AABA</td>\n",
       "      <td>2914502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4240</th>\n",
       "      <td>ZUMZ</td>\n",
       "      <td>9882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>ZUO</td>\n",
       "      <td>168444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>ZYNE</td>\n",
       "      <td>36008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4243 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     underlying  quantity\n",
       "0             A    166644\n",
       "1            AA    612596\n",
       "2          AABA   2914502\n",
       "...         ...       ...\n",
       "4240       ZUMZ      9882\n",
       "4241        ZUO    168444\n",
       "4242       ZYNE     36008\n",
       "\n",
       "[4243 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_report = df_occ.groupby('underlying')['quantity'].sum().to_frame().reset_index()\n",
    "\n",
    "df_report = df_occ.groupby('underlying')['quantity'].sum().to_frame().reset_index()\n",
    "df_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 100 ETFs (non-volatility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section we used the `.groupby()` function to get the aggregated data we wanted.  Since the backtesting we will eventually do will focus on liquid (high volume), non-volatility ETFs, let's see if we can restrict ourselves to those underlyings.  In particular, the goal of this section is to find the 100 highest volume, non-volatility, ETFs.\n",
    "\n",
    "We will start by reading in a master list of ETFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_etf = pd.read_csv('data/etf_list.csv')\n",
    "\n",
    "df_etf = pd.read_csv('../data/etf_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>issuer</th>\n",
       "      <th>expense_ratio</th>\n",
       "      <th>aum</th>\n",
       "      <th>spread</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td>SPDR S&amp;P 500 ETF Trust</td>\n",
       "      <td>State Street Global Advisors</td>\n",
       "      <td>0.09%</td>\n",
       "      <td>$275.42B</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>Equity: U.S. - Large Cap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IVV</td>\n",
       "      <td>iShares Core S&amp;P 500 ETF</td>\n",
       "      <td>BlackRock</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>$155.86B</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>Equity: U.S. - Large Cap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VTI</td>\n",
       "      <td>Vanguard Total Stock Market ETF</td>\n",
       "      <td>Vanguard</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>$103.58B</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>Equity: U.S. - Total Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>ADZCF</td>\n",
       "      <td>DB Agriculture Short ETN</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>0.75%</td>\n",
       "      <td>$250.85K</td>\n",
       "      <td>72.50%</td>\n",
       "      <td>Inverse Commodities: Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>DEE</td>\n",
       "      <td>DB Commodity Double Short ETN</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>0.75%</td>\n",
       "      <td>$221.25K</td>\n",
       "      <td>73.72%</td>\n",
       "      <td>Inverse Commodities: Broad Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>FRLG</td>\n",
       "      <td>Large Cap Growth Index-Linked ETN</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>1.46%</td>\n",
       "      <td>$NaN</td>\n",
       "      <td>0.54%</td>\n",
       "      <td>Leveraged Equity: U.S. - Large Cap Growth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol                               name                        issuer  \\\n",
       "0       SPY             SPDR S&P 500 ETF Trust  State Street Global Advisors   \n",
       "1       IVV           iShares Core S&P 500 ETF                     BlackRock   \n",
       "2       VTI    Vanguard Total Stock Market ETF                      Vanguard   \n",
       "...     ...                                ...                           ...   \n",
       "2157  ADZCF           DB Agriculture Short ETN                 Deutsche Bank   \n",
       "2158    DEE      DB Commodity Double Short ETN                 Deutsche Bank   \n",
       "2159   FRLG  Large Cap Growth Index-Linked ETN                 Goldman Sachs   \n",
       "\n",
       "     expense_ratio       aum  spread  \\\n",
       "0            0.09%  $275.42B   0.00%   \n",
       "1            0.04%  $155.86B   0.01%   \n",
       "2            0.04%  $103.58B   0.01%   \n",
       "...            ...       ...     ...   \n",
       "2157         0.75%  $250.85K  72.50%   \n",
       "2158         0.75%  $221.25K  73.72%   \n",
       "2159         1.46%      $NaN   0.54%   \n",
       "\n",
       "                                        segment  \n",
       "0                      Equity: U.S. - Large Cap  \n",
       "1                      Equity: U.S. - Large Cap  \n",
       "2                   Equity: U.S. - Total Market  \n",
       "...                                         ...  \n",
       "2157           Inverse Commodities: Agriculture  \n",
       "2158          Inverse Commodities: Broad Market  \n",
       "2159  Leveraged Equity: U.S. - Large Cap Growth  \n",
       "\n",
       "[2160 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_etf\n",
    "\n",
    "df_etf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the non-volatility ETFs we will perform a `DataFrame` masking operation on the `segment` column.  But first we will need to lowercase all the letters in that column.  We use the `Series.str.lower()` method for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_etf['segment'] = df_etf['segment'].str.lower()\n",
    "\n",
    "df_etf['segment'] = df_etf['segment'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>issuer</th>\n",
       "      <th>expense_ratio</th>\n",
       "      <th>aum</th>\n",
       "      <th>spread</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td>SPDR S&amp;P 500 ETF Trust</td>\n",
       "      <td>State Street Global Advisors</td>\n",
       "      <td>0.09%</td>\n",
       "      <td>$275.42B</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>equity: u.s. - large cap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IVV</td>\n",
       "      <td>iShares Core S&amp;P 500 ETF</td>\n",
       "      <td>BlackRock</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>$155.86B</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>equity: u.s. - large cap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VTI</td>\n",
       "      <td>Vanguard Total Stock Market ETF</td>\n",
       "      <td>Vanguard</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>$103.58B</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>equity: u.s. - total market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>ADZCF</td>\n",
       "      <td>DB Agriculture Short ETN</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>0.75%</td>\n",
       "      <td>$250.85K</td>\n",
       "      <td>72.50%</td>\n",
       "      <td>inverse commodities: agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>DEE</td>\n",
       "      <td>DB Commodity Double Short ETN</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>0.75%</td>\n",
       "      <td>$221.25K</td>\n",
       "      <td>73.72%</td>\n",
       "      <td>inverse commodities: broad market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>FRLG</td>\n",
       "      <td>Large Cap Growth Index-Linked ETN</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>1.46%</td>\n",
       "      <td>$NaN</td>\n",
       "      <td>0.54%</td>\n",
       "      <td>leveraged equity: u.s. - large cap growth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol                               name                        issuer  \\\n",
       "0       SPY             SPDR S&P 500 ETF Trust  State Street Global Advisors   \n",
       "1       IVV           iShares Core S&P 500 ETF                     BlackRock   \n",
       "2       VTI    Vanguard Total Stock Market ETF                      Vanguard   \n",
       "...     ...                                ...                           ...   \n",
       "2157  ADZCF           DB Agriculture Short ETN                 Deutsche Bank   \n",
       "2158    DEE      DB Commodity Double Short ETN                 Deutsche Bank   \n",
       "2159   FRLG  Large Cap Growth Index-Linked ETN                 Goldman Sachs   \n",
       "\n",
       "     expense_ratio       aum  spread  \\\n",
       "0            0.09%  $275.42B   0.00%   \n",
       "1            0.04%  $155.86B   0.01%   \n",
       "2            0.04%  $103.58B   0.01%   \n",
       "...            ...       ...     ...   \n",
       "2157         0.75%  $250.85K  72.50%   \n",
       "2158         0.75%  $221.25K  73.72%   \n",
       "2159         1.46%      $NaN   0.54%   \n",
       "\n",
       "                                        segment  \n",
       "0                      equity: u.s. - large cap  \n",
       "1                      equity: u.s. - large cap  \n",
       "2                   equity: u.s. - total market  \n",
       "...                                         ...  \n",
       "2157           inverse commodities: agriculture  \n",
       "2158          inverse commodities: broad market  \n",
       "2159  leveraged equity: u.s. - large cap growth  \n",
       "\n",
       "[2160 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_etf\n",
    "\n",
    "df_etf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use the `Series.str.contains()` method to isolate all the non-volatility ETFs.  Notice that this utilizes boolean indexing of dataframes.  \n",
    "\n",
    "**Note:** This step requires knowledge of the dataset that you wouldn't necessarily have unless I gave it to you.  The way I came up with it was through exploration of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_non_vol_etf = df_etf[~df_etf['segment'].str.contains('volatility')]\n",
    "\n",
    "df_non_vol_etf = df_etf[~df_etf['segment'].str.contains('volatility')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td>SPDR S&amp;P 500 ETF Trust</td>\n",
       "      <td>107351530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IVV</td>\n",
       "      <td>iShares Core S&amp;P 500 ETF</td>\n",
       "      <td>22838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VTI</td>\n",
       "      <td>Vanguard Total Stock Market ETF</td>\n",
       "      <td>21084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>REW</td>\n",
       "      <td>ProShares UltraShort Technology</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>SSG</td>\n",
       "      <td>ProShares UltraShort Semiconductors</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>GDXS</td>\n",
       "      <td>Proshares Ultrashort Gold Miners</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol                                 name   quantity\n",
       "0      SPY               SPDR S&P 500 ETF Trust  107351530\n",
       "1      IVV             iShares Core S&P 500 ETF      22838\n",
       "2      VTI      Vanguard Total Stock Market ETF      21084\n",
       "..     ...                                  ...        ...\n",
       "610    REW      ProShares UltraShort Technology         20\n",
       "611    SSG  ProShares UltraShort Semiconductors       1050\n",
       "612   GDXS     Proshares Ultrashort Gold Miners        152\n",
       "\n",
       "[613 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##> df_non_vol_etf.join(df_report, how = 'inner')\n",
    "\n",
    "df_joined = \\\n",
    "    df_non_vol_etf.merge(df_report, how='inner', left_on='symbol', right_on='underlying')\\\n",
    "    [['symbol', 'name', 'quantity']]\n",
    "\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Challenge:** Combine `.sort_values()` with `.head()` to find the 100 highest volume non-volatility ETFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
